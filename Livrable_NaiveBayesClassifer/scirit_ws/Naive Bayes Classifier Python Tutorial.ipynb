{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Salary  Purchased\n",
       "0   19   19000          0\n",
       "1   35   20000          0\n",
       "2   26   43000          0\n",
       "3   27   57000          0\n",
       "4   19   76000          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the dataset\n",
    "dataset = pd.read_csv('NaiveBayes.csv')\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[    19,  19000],\n",
       "        [    35,  20000],\n",
       "        [    26,  43000],\n",
       "        [    27,  57000],\n",
       "        [    19,  76000],\n",
       "        [    27,  58000],\n",
       "        [    27,  84000],\n",
       "        [    32, 150000],\n",
       "        [    25,  33000],\n",
       "        [    35,  65000],\n",
       "        [    26,  80000],\n",
       "        [    26,  52000],\n",
       "        [    20,  86000],\n",
       "        [    32,  18000],\n",
       "        [    18,  82000],\n",
       "        [    29,  80000],\n",
       "        [    47,  25000],\n",
       "        [    45,  26000],\n",
       "        [    46,  28000],\n",
       "        [    48,  29000],\n",
       "        [    45,  22000],\n",
       "        [    47,  49000],\n",
       "        [    48,  41000],\n",
       "        [    45,  22000],\n",
       "        [    46,  23000],\n",
       "        [    47,  20000],\n",
       "        [    49,  28000],\n",
       "        [    47,  30000],\n",
       "        [    29,  43000],\n",
       "        [    31,  18000],\n",
       "        [    31,  74000],\n",
       "        [    27, 137000],\n",
       "        [    21,  16000],\n",
       "        [    28,  44000],\n",
       "        [    27,  90000],\n",
       "        [    35,  27000],\n",
       "        [    33,  28000],\n",
       "        [    30,  49000],\n",
       "        [    26,  72000],\n",
       "        [    27,  31000],\n",
       "        [    27,  17000],\n",
       "        [    33,  51000],\n",
       "        [    35, 108000],\n",
       "        [    30,  15000],\n",
       "        [    28,  84000],\n",
       "        [    23,  20000],\n",
       "        [    25,  79000],\n",
       "        [    27,  54000],\n",
       "        [    30, 135000],\n",
       "        [    31,  89000],\n",
       "        [    24,  32000],\n",
       "        [    18,  44000],\n",
       "        [    29,  83000],\n",
       "        [    35,  23000],\n",
       "        [    27,  58000],\n",
       "        [    24,  55000],\n",
       "        [    23,  48000],\n",
       "        [    28,  79000],\n",
       "        [    22,  18000],\n",
       "        [    32, 117000],\n",
       "        [    27,  20000],\n",
       "        [    25,  87000],\n",
       "        [    23,  66000],\n",
       "        [    32, 120000],\n",
       "        [    59,  83000],\n",
       "        [    24,  58000],\n",
       "        [    24,  19000],\n",
       "        [    23,  82000],\n",
       "        [    22,  63000],\n",
       "        [    31,  68000],\n",
       "        [    25,  80000],\n",
       "        [    24,  27000],\n",
       "        [    20,  23000],\n",
       "        [    33, 113000],\n",
       "        [    32,  18000],\n",
       "        [    34, 112000],\n",
       "        [    18,  52000],\n",
       "        [    22,  27000],\n",
       "        [    28,  87000],\n",
       "        [    26,  17000],\n",
       "        [    30,  80000],\n",
       "        [    39,  42000],\n",
       "        [    20,  49000],\n",
       "        [    35,  88000],\n",
       "        [    30,  62000],\n",
       "        [    31, 118000],\n",
       "        [    24,  55000],\n",
       "        [    28,  85000],\n",
       "        [    26,  81000],\n",
       "        [    35,  50000],\n",
       "        [    22,  81000],\n",
       "        [    30, 116000],\n",
       "        [    26,  15000],\n",
       "        [    29,  28000],\n",
       "        [    29,  83000],\n",
       "        [    35,  44000],\n",
       "        [    35,  25000],\n",
       "        [    28, 123000],\n",
       "        [    35,  73000],\n",
       "        [    28,  37000],\n",
       "        [    27,  88000],\n",
       "        [    28,  59000],\n",
       "        [    32,  86000],\n",
       "        [    33, 149000],\n",
       "        [    19,  21000],\n",
       "        [    21,  72000],\n",
       "        [    26,  35000],\n",
       "        [    27,  89000],\n",
       "        [    26,  86000],\n",
       "        [    38,  80000],\n",
       "        [    39,  71000],\n",
       "        [    37,  71000],\n",
       "        [    38,  61000],\n",
       "        [    37,  55000],\n",
       "        [    42,  80000],\n",
       "        [    40,  57000],\n",
       "        [    35,  75000],\n",
       "        [    36,  52000],\n",
       "        [    40,  59000],\n",
       "        [    41,  59000],\n",
       "        [    36,  75000],\n",
       "        [    37,  72000],\n",
       "        [    40,  75000],\n",
       "        [    35,  53000],\n",
       "        [    41,  51000],\n",
       "        [    39,  61000],\n",
       "        [    42,  65000],\n",
       "        [    26,  32000],\n",
       "        [    30,  17000],\n",
       "        [    26,  84000],\n",
       "        [    31,  58000],\n",
       "        [    33,  31000],\n",
       "        [    30,  87000],\n",
       "        [    21,  68000],\n",
       "        [    28,  55000],\n",
       "        [    23,  63000],\n",
       "        [    20,  82000],\n",
       "        [    30, 107000],\n",
       "        [    28,  59000],\n",
       "        [    19,  25000],\n",
       "        [    19,  85000],\n",
       "        [    18,  68000],\n",
       "        [    35,  59000],\n",
       "        [    30,  89000],\n",
       "        [    34,  25000],\n",
       "        [    24,  89000],\n",
       "        [    27,  96000],\n",
       "        [    41,  30000],\n",
       "        [    29,  61000],\n",
       "        [    20,  74000],\n",
       "        [    26,  15000],\n",
       "        [    41,  45000],\n",
       "        [    31,  76000],\n",
       "        [    36,  50000],\n",
       "        [    40,  47000],\n",
       "        [    31,  15000],\n",
       "        [    46,  59000],\n",
       "        [    29,  75000],\n",
       "        [    26,  30000],\n",
       "        [    32, 135000],\n",
       "        [    32, 100000],\n",
       "        [    25,  90000],\n",
       "        [    37,  33000],\n",
       "        [    35,  38000],\n",
       "        [    33,  69000],\n",
       "        [    18,  86000],\n",
       "        [    22,  55000],\n",
       "        [    35,  71000],\n",
       "        [    29, 148000],\n",
       "        [    29,  47000],\n",
       "        [    21,  88000],\n",
       "        [    34, 115000],\n",
       "        [    26, 118000],\n",
       "        [    34,  43000],\n",
       "        [    34,  72000],\n",
       "        [    23,  28000],\n",
       "        [    35,  47000],\n",
       "        [    25,  22000],\n",
       "        [    24,  23000],\n",
       "        [    31,  34000],\n",
       "        [    26,  16000],\n",
       "        [    31,  71000],\n",
       "        [    32, 117000],\n",
       "        [    33,  43000],\n",
       "        [    33,  60000],\n",
       "        [    31,  66000],\n",
       "        [    20,  82000],\n",
       "        [    33,  41000],\n",
       "        [    35,  72000],\n",
       "        [    28,  32000],\n",
       "        [    24,  84000],\n",
       "        [    19,  26000],\n",
       "        [    29,  43000],\n",
       "        [    19,  70000],\n",
       "        [    28,  89000],\n",
       "        [    34,  43000],\n",
       "        [    30,  79000],\n",
       "        [    20,  36000],\n",
       "        [    26,  80000],\n",
       "        [    35,  22000],\n",
       "        [    35,  39000],\n",
       "        [    49,  74000],\n",
       "        [    39, 134000],\n",
       "        [    41,  71000],\n",
       "        [    58, 101000],\n",
       "        [    47,  47000],\n",
       "        [    55, 130000],\n",
       "        [    52, 114000],\n",
       "        [    40, 142000],\n",
       "        [    46,  22000],\n",
       "        [    48,  96000],\n",
       "        [    52, 150000],\n",
       "        [    59,  42000],\n",
       "        [    35,  58000],\n",
       "        [    47,  43000],\n",
       "        [    60, 108000],\n",
       "        [    49,  65000],\n",
       "        [    40,  78000],\n",
       "        [    46,  96000],\n",
       "        [    59, 143000],\n",
       "        [    41,  80000],\n",
       "        [    35,  91000],\n",
       "        [    37, 144000],\n",
       "        [    60, 102000],\n",
       "        [    35,  60000],\n",
       "        [    37,  53000],\n",
       "        [    36, 126000],\n",
       "        [    56, 133000],\n",
       "        [    40,  72000],\n",
       "        [    42,  80000],\n",
       "        [    35, 147000],\n",
       "        [    39,  42000],\n",
       "        [    40, 107000],\n",
       "        [    49,  86000],\n",
       "        [    38, 112000],\n",
       "        [    46,  79000],\n",
       "        [    40,  57000],\n",
       "        [    37,  80000],\n",
       "        [    46,  82000],\n",
       "        [    53, 143000],\n",
       "        [    42, 149000],\n",
       "        [    38,  59000],\n",
       "        [    50,  88000],\n",
       "        [    56, 104000],\n",
       "        [    41,  72000],\n",
       "        [    51, 146000],\n",
       "        [    35,  50000],\n",
       "        [    57, 122000],\n",
       "        [    41,  52000],\n",
       "        [    35,  97000],\n",
       "        [    44,  39000],\n",
       "        [    37,  52000],\n",
       "        [    48, 134000],\n",
       "        [    37, 146000],\n",
       "        [    50,  44000],\n",
       "        [    52,  90000],\n",
       "        [    41,  72000],\n",
       "        [    40,  57000],\n",
       "        [    58,  95000],\n",
       "        [    45, 131000],\n",
       "        [    35,  77000],\n",
       "        [    36, 144000],\n",
       "        [    55, 125000],\n",
       "        [    35,  72000],\n",
       "        [    48,  90000],\n",
       "        [    42, 108000],\n",
       "        [    40,  75000],\n",
       "        [    37,  74000],\n",
       "        [    47, 144000],\n",
       "        [    40,  61000],\n",
       "        [    43, 133000],\n",
       "        [    59,  76000],\n",
       "        [    60,  42000],\n",
       "        [    39, 106000],\n",
       "        [    57,  26000],\n",
       "        [    57,  74000],\n",
       "        [    38,  71000],\n",
       "        [    49,  88000],\n",
       "        [    52,  38000],\n",
       "        [    50,  36000],\n",
       "        [    59,  88000],\n",
       "        [    35,  61000],\n",
       "        [    37,  70000],\n",
       "        [    52,  21000],\n",
       "        [    48, 141000],\n",
       "        [    37,  93000],\n",
       "        [    37,  62000],\n",
       "        [    48, 138000],\n",
       "        [    41,  79000],\n",
       "        [    37,  78000],\n",
       "        [    39, 134000],\n",
       "        [    49,  89000],\n",
       "        [    55,  39000],\n",
       "        [    37,  77000],\n",
       "        [    35,  57000],\n",
       "        [    36,  63000],\n",
       "        [    42,  73000],\n",
       "        [    43, 112000],\n",
       "        [    45,  79000],\n",
       "        [    46, 117000],\n",
       "        [    58,  38000],\n",
       "        [    48,  74000],\n",
       "        [    37, 137000],\n",
       "        [    37,  79000],\n",
       "        [    40,  60000],\n",
       "        [    42,  54000],\n",
       "        [    51, 134000],\n",
       "        [    47, 113000],\n",
       "        [    36, 125000],\n",
       "        [    38,  50000],\n",
       "        [    42,  70000],\n",
       "        [    39,  96000],\n",
       "        [    38,  50000],\n",
       "        [    49, 141000],\n",
       "        [    39,  79000],\n",
       "        [    39,  75000],\n",
       "        [    54, 104000],\n",
       "        [    35,  55000],\n",
       "        [    45,  32000],\n",
       "        [    36,  60000],\n",
       "        [    52, 138000],\n",
       "        [    53,  82000],\n",
       "        [    41,  52000],\n",
       "        [    48,  30000],\n",
       "        [    48, 131000],\n",
       "        [    41,  60000],\n",
       "        [    41,  72000],\n",
       "        [    42,  75000],\n",
       "        [    36, 118000],\n",
       "        [    47, 107000],\n",
       "        [    38,  51000],\n",
       "        [    48, 119000],\n",
       "        [    42,  65000],\n",
       "        [    40,  65000],\n",
       "        [    57,  60000],\n",
       "        [    36,  54000],\n",
       "        [    58, 144000],\n",
       "        [    35,  79000],\n",
       "        [    38,  55000],\n",
       "        [    39, 122000],\n",
       "        [    53, 104000],\n",
       "        [    35,  75000],\n",
       "        [    38,  65000],\n",
       "        [    47,  51000],\n",
       "        [    47, 105000],\n",
       "        [    41,  63000],\n",
       "        [    53,  72000],\n",
       "        [    54, 108000],\n",
       "        [    39,  77000],\n",
       "        [    38,  61000],\n",
       "        [    38, 113000],\n",
       "        [    37,  75000],\n",
       "        [    42,  90000],\n",
       "        [    37,  57000],\n",
       "        [    36,  99000],\n",
       "        [    60,  34000],\n",
       "        [    54,  70000],\n",
       "        [    41,  72000],\n",
       "        [    40,  71000],\n",
       "        [    42,  54000],\n",
       "        [    43, 129000],\n",
       "        [    53,  34000],\n",
       "        [    47,  50000],\n",
       "        [    42,  79000],\n",
       "        [    42, 104000],\n",
       "        [    59,  29000],\n",
       "        [    58,  47000],\n",
       "        [    46,  88000],\n",
       "        [    38,  71000],\n",
       "        [    54,  26000],\n",
       "        [    60,  46000],\n",
       "        [    60,  83000],\n",
       "        [    39,  73000],\n",
       "        [    59, 130000],\n",
       "        [    37,  80000],\n",
       "        [    46,  32000],\n",
       "        [    46,  74000],\n",
       "        [    42,  53000],\n",
       "        [    41,  87000],\n",
       "        [    58,  23000],\n",
       "        [    42,  64000],\n",
       "        [    48,  33000],\n",
       "        [    44, 139000],\n",
       "        [    49,  28000],\n",
       "        [    57,  33000],\n",
       "        [    56,  60000],\n",
       "        [    49,  39000],\n",
       "        [    39,  71000],\n",
       "        [    47,  34000],\n",
       "        [    48,  35000],\n",
       "        [    48,  33000],\n",
       "        [    47,  23000],\n",
       "        [    45,  45000],\n",
       "        [    60,  42000],\n",
       "        [    39,  59000],\n",
       "        [    46,  41000],\n",
       "        [    51,  23000],\n",
       "        [    50,  20000],\n",
       "        [    36,  33000],\n",
       "        [    49,  36000]], dtype=int64),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into inputs and outputs\n",
    "X = dataset.iloc[:, [0,1]].values\n",
    "y = dataset.iloc[:, 2].values\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.0-1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\utilisateur2\\anaconda3\\envs\\devsalah_3classification\\lib\\site-packages (from scikit-learn) (1.26.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.12.0-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     --------------------------- ------------ 41.0/60.4 kB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 60.4/60.4 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.4.0-1-cp310-cp310-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/10.6 MB 5.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.4/10.6 MB 5.4 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.4/10.6 MB 5.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.9/10.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.5/10.6 MB 6.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.2/10.6 MB 8.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 9.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.1/10.6 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.0/10.6 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.8/10.6 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.2/10.6 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.9/10.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.5/10.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.3/10.6 MB 13.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.5/10.6 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 15.2 MB/s eta 0:00:00\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Downloading scipy-1.12.0-cp310-cp310-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/46.2 MB 20.9 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 2.3/46.2 MB 24.4 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 2.7/46.2 MB 21.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 3.5/46.2 MB 18.7 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 4.6/46.2 MB 19.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 5.7/46.2 MB 20.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 6.7/46.2 MB 20.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 7.9/46.2 MB 21.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 8.9/46.2 MB 21.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 9.8/46.2 MB 20.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 10.7/46.2 MB 21.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 11.8/46.2 MB 21.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 13.0/46.2 MB 22.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 13.2/46.2 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 14.0/46.2 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 14.7/46.2 MB 19.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 15.9/46.2 MB 19.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 16.2/46.2 MB 18.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 16.9/46.2 MB 18.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 17.7/46.2 MB 18.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 18.9/46.2 MB 18.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 19.9/46.2 MB 18.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 20.8/46.2 MB 18.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 22.0/46.2 MB 18.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 22.7/46.2 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 23.0/46.2 MB 16.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.7/46.2 MB 17.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.6/46.2 MB 17.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 25.5/46.2 MB 17.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 26.2/46.2 MB 17.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.8/46.2 MB 18.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 27.5/46.2 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.1/46.2 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.8/46.2 MB 16.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.6/46.2 MB 16.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 30.2/46.2 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 31.3/46.2 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 31.9/46.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 32.3/46.2 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 33.0/46.2 MB 15.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 33.9/46.2 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 34.8/46.2 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 35.5/46.2 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 36.1/46.2 MB 15.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.0/46.2 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.9/46.2 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.7/46.2 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.6/46.2 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 40.1/46.2 MB 16.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.7/46.2 MB 16.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 41.5/46.2 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.8/46.2 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.4/46.2 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.1/46.2 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.0/46.2 MB 15.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.3/46.2 MB 14.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 45.0/46.2 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.6/46.2 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 13.9 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.4.0 scipy-1.12.0 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[    44,  39000],\n",
       "        [    32, 120000],\n",
       "        [    38,  50000],\n",
       "        [    32, 135000],\n",
       "        [    52,  21000],\n",
       "        [    53, 104000],\n",
       "        [    39,  42000],\n",
       "        [    38,  61000],\n",
       "        [    36,  50000],\n",
       "        [    36,  63000],\n",
       "        [    35,  25000],\n",
       "        [    35,  50000],\n",
       "        [    42,  73000],\n",
       "        [    47,  49000],\n",
       "        [    59,  29000],\n",
       "        [    49,  65000],\n",
       "        [    45, 131000],\n",
       "        [    31,  89000],\n",
       "        [    46,  82000],\n",
       "        [    47,  51000],\n",
       "        [    26,  15000],\n",
       "        [    60, 102000],\n",
       "        [    38, 112000],\n",
       "        [    40, 107000],\n",
       "        [    42,  53000],\n",
       "        [    35,  59000],\n",
       "        [    48,  41000],\n",
       "        [    48, 134000],\n",
       "        [    38, 113000],\n",
       "        [    29, 148000],\n",
       "        [    26,  15000],\n",
       "        [    60,  42000],\n",
       "        [    24,  19000],\n",
       "        [    42, 149000],\n",
       "        [    46,  96000],\n",
       "        [    28,  59000],\n",
       "        [    39,  96000],\n",
       "        [    28,  89000],\n",
       "        [    41,  72000],\n",
       "        [    45,  26000],\n",
       "        [    33,  69000],\n",
       "        [    20,  82000],\n",
       "        [    31,  74000],\n",
       "        [    42,  80000],\n",
       "        [    35,  72000],\n",
       "        [    33, 149000],\n",
       "        [    40,  71000],\n",
       "        [    51, 146000],\n",
       "        [    46,  79000],\n",
       "        [    35,  75000],\n",
       "        [    38,  51000],\n",
       "        [    36,  75000],\n",
       "        [    37,  78000],\n",
       "        [    38,  61000],\n",
       "        [    60, 108000],\n",
       "        [    20,  82000],\n",
       "        [    57,  74000],\n",
       "        [    42,  65000],\n",
       "        [    26,  80000],\n",
       "        [    46, 117000],\n",
       "        [    35,  61000],\n",
       "        [    21,  68000],\n",
       "        [    28,  44000],\n",
       "        [    41,  87000],\n",
       "        [    37,  33000],\n",
       "        [    27,  90000],\n",
       "        [    39,  42000],\n",
       "        [    28, 123000],\n",
       "        [    31, 118000],\n",
       "        [    25,  87000],\n",
       "        [    35,  71000],\n",
       "        [    37,  70000],\n",
       "        [    35,  39000],\n",
       "        [    47,  23000],\n",
       "        [    35, 147000],\n",
       "        [    48, 138000],\n",
       "        [    26,  86000],\n",
       "        [    25,  79000],\n",
       "        [    52, 138000],\n",
       "        [    51,  23000],\n",
       "        [    35,  60000],\n",
       "        [    33, 113000],\n",
       "        [    30, 107000],\n",
       "        [    48,  33000],\n",
       "        [    41,  80000],\n",
       "        [    48,  96000],\n",
       "        [    31,  18000],\n",
       "        [    31,  71000],\n",
       "        [    43, 129000],\n",
       "        [    59,  76000],\n",
       "        [    18,  44000],\n",
       "        [    36, 118000],\n",
       "        [    42,  90000],\n",
       "        [    47,  30000],\n",
       "        [    26,  43000],\n",
       "        [    40,  78000],\n",
       "        [    46,  59000],\n",
       "        [    59,  42000],\n",
       "        [    46,  74000],\n",
       "        [    35,  91000],\n",
       "        [    28,  59000],\n",
       "        [    40,  57000],\n",
       "        [    59, 143000],\n",
       "        [    57,  26000],\n",
       "        [    52,  38000],\n",
       "        [    47, 113000],\n",
       "        [    53, 143000],\n",
       "        [    35,  27000],\n",
       "        [    58, 101000],\n",
       "        [    45,  45000],\n",
       "        [    23,  82000],\n",
       "        [    46,  23000],\n",
       "        [    42,  65000],\n",
       "        [    28,  84000],\n",
       "        [    38,  59000],\n",
       "        [    26,  84000],\n",
       "        [    29,  28000],\n",
       "        [    37,  71000],\n",
       "        [    22,  55000],\n",
       "        [    48,  35000],\n",
       "        [    49,  28000],\n",
       "        [    38,  65000],\n",
       "        [    27,  17000],\n",
       "        [    46,  28000],\n",
       "        [    48, 141000],\n",
       "        [    26,  17000],\n",
       "        [    35,  97000],\n",
       "        [    39,  59000],\n",
       "        [    24,  27000],\n",
       "        [    32,  18000],\n",
       "        [    46,  88000],\n",
       "        [    35,  58000],\n",
       "        [    56,  60000],\n",
       "        [    47,  34000],\n",
       "        [    40,  72000],\n",
       "        [    32, 100000],\n",
       "        [    19,  21000],\n",
       "        [    25,  90000],\n",
       "        [    35,  88000],\n",
       "        [    28,  32000],\n",
       "        [    50,  20000],\n",
       "        [    40,  59000],\n",
       "        [    50,  44000],\n",
       "        [    35,  72000],\n",
       "        [    40, 142000],\n",
       "        [    46,  32000],\n",
       "        [    39,  71000],\n",
       "        [    20,  74000],\n",
       "        [    29,  75000],\n",
       "        [    31,  76000],\n",
       "        [    47,  25000],\n",
       "        [    40,  61000],\n",
       "        [    34, 112000],\n",
       "        [    38,  80000],\n",
       "        [    42,  75000],\n",
       "        [    47,  47000],\n",
       "        [    39,  75000],\n",
       "        [    19,  25000],\n",
       "        [    37,  80000],\n",
       "        [    36,  60000],\n",
       "        [    41,  52000],\n",
       "        [    36, 125000],\n",
       "        [    48,  29000],\n",
       "        [    36, 126000],\n",
       "        [    51, 134000],\n",
       "        [    27,  57000],\n",
       "        [    38,  71000],\n",
       "        [    39,  61000],\n",
       "        [    22,  27000],\n",
       "        [    33,  60000],\n",
       "        [    48,  74000],\n",
       "        [    58,  23000],\n",
       "        [    53,  72000],\n",
       "        [    32, 117000],\n",
       "        [    54,  70000],\n",
       "        [    30,  80000],\n",
       "        [    58,  95000],\n",
       "        [    26,  52000],\n",
       "        [    45,  79000],\n",
       "        [    24,  55000],\n",
       "        [    40,  75000],\n",
       "        [    33,  28000],\n",
       "        [    44, 139000],\n",
       "        [    22,  18000],\n",
       "        [    33,  51000],\n",
       "        [    43, 133000],\n",
       "        [    24,  32000],\n",
       "        [    46,  22000],\n",
       "        [    35,  55000],\n",
       "        [    54, 104000],\n",
       "        [    48, 119000],\n",
       "        [    35,  53000],\n",
       "        [    37, 144000],\n",
       "        [    23,  66000],\n",
       "        [    37, 137000],\n",
       "        [    31,  58000],\n",
       "        [    33,  41000],\n",
       "        [    45,  22000],\n",
       "        [    30,  15000],\n",
       "        [    19,  19000],\n",
       "        [    49,  74000],\n",
       "        [    39, 122000],\n",
       "        [    35,  73000],\n",
       "        [    39,  71000],\n",
       "        [    24,  23000],\n",
       "        [    41,  72000],\n",
       "        [    29,  83000],\n",
       "        [    54,  26000],\n",
       "        [    35,  44000],\n",
       "        [    37,  75000],\n",
       "        [    29,  47000],\n",
       "        [    31,  68000],\n",
       "        [    42,  54000],\n",
       "        [    30, 135000],\n",
       "        [    52, 114000],\n",
       "        [    50,  36000],\n",
       "        [    56, 133000],\n",
       "        [    29,  61000],\n",
       "        [    30,  89000],\n",
       "        [    26,  16000],\n",
       "        [    33,  31000],\n",
       "        [    41,  72000],\n",
       "        [    36,  33000],\n",
       "        [    55, 125000],\n",
       "        [    48, 131000],\n",
       "        [    41,  71000],\n",
       "        [    30,  62000],\n",
       "        [    37,  72000],\n",
       "        [    41,  63000],\n",
       "        [    58,  47000],\n",
       "        [    30, 116000],\n",
       "        [    20,  49000],\n",
       "        [    37,  74000],\n",
       "        [    41,  59000],\n",
       "        [    49,  89000],\n",
       "        [    28,  79000],\n",
       "        [    53,  82000],\n",
       "        [    40,  57000],\n",
       "        [    60,  34000],\n",
       "        [    35, 108000],\n",
       "        [    21,  72000],\n",
       "        [    38,  71000],\n",
       "        [    39, 106000],\n",
       "        [    37,  57000],\n",
       "        [    26,  72000],\n",
       "        [    35,  23000],\n",
       "        [    54, 108000],\n",
       "        [    30,  17000],\n",
       "        [    39, 134000],\n",
       "        [    29,  43000],\n",
       "        [    33,  43000],\n",
       "        [    35,  38000],\n",
       "        [    41,  45000],\n",
       "        [    41,  72000],\n",
       "        [    39, 134000],\n",
       "        [    27, 137000],\n",
       "        [    21,  16000],\n",
       "        [    26,  32000],\n",
       "        [    31,  66000],\n",
       "        [    39,  73000],\n",
       "        [    41,  79000],\n",
       "        [    47,  50000],\n",
       "        [    41,  30000],\n",
       "        [    37,  93000],\n",
       "        [    60,  46000],\n",
       "        [    25,  22000],\n",
       "        [    28,  37000],\n",
       "        [    38,  55000],\n",
       "        [    36,  54000],\n",
       "        [    20,  36000],\n",
       "        [    56, 104000],\n",
       "        [    40,  57000],\n",
       "        [    42, 108000],\n",
       "        [    20,  23000],\n",
       "        [    40,  65000],\n",
       "        [    47,  20000],\n",
       "        [    18,  86000],\n",
       "        [    35,  79000],\n",
       "        [    57,  33000],\n",
       "        [    34,  72000],\n",
       "        [    49,  39000],\n",
       "        [    27,  31000],\n",
       "        [    19,  70000],\n",
       "        [    39,  79000],\n",
       "        [    26,  81000],\n",
       "        [    25,  80000],\n",
       "        [    28,  85000],\n",
       "        [    55,  39000],\n",
       "        [    50,  88000],\n",
       "        [    49,  88000],\n",
       "        [    52, 150000],\n",
       "        [    35,  65000],\n",
       "        [    42,  54000],\n",
       "        [    34,  43000],\n",
       "        [    37,  52000],\n",
       "        [    48,  30000],\n",
       "        [    29,  43000],\n",
       "        [    36,  52000],\n",
       "        [    27,  54000],\n",
       "        [    26, 118000]], dtype=int64),\n",
       " array([[    30,  87000],\n",
       "        [    38,  50000],\n",
       "        [    35,  75000],\n",
       "        [    30,  79000],\n",
       "        [    35,  50000],\n",
       "        [    27,  20000],\n",
       "        [    31,  15000],\n",
       "        [    36, 144000],\n",
       "        [    18,  68000],\n",
       "        [    47,  43000],\n",
       "        [    30,  49000],\n",
       "        [    28,  55000],\n",
       "        [    37,  55000],\n",
       "        [    39,  77000],\n",
       "        [    20,  86000],\n",
       "        [    32, 117000],\n",
       "        [    37,  77000],\n",
       "        [    19,  85000],\n",
       "        [    55, 130000],\n",
       "        [    35,  22000],\n",
       "        [    35,  47000],\n",
       "        [    47, 144000],\n",
       "        [    41,  51000],\n",
       "        [    47, 105000],\n",
       "        [    23,  28000],\n",
       "        [    49, 141000],\n",
       "        [    28,  87000],\n",
       "        [    29,  80000],\n",
       "        [    37,  62000],\n",
       "        [    32,  86000],\n",
       "        [    21,  88000],\n",
       "        [    37,  79000],\n",
       "        [    57,  60000],\n",
       "        [    37,  53000],\n",
       "        [    24,  58000],\n",
       "        [    18,  52000],\n",
       "        [    22,  81000],\n",
       "        [    34,  43000],\n",
       "        [    31,  34000],\n",
       "        [    49,  36000],\n",
       "        [    27,  88000],\n",
       "        [    41,  52000],\n",
       "        [    27,  84000],\n",
       "        [    35,  20000],\n",
       "        [    43, 112000],\n",
       "        [    27,  58000],\n",
       "        [    37,  80000],\n",
       "        [    52,  90000],\n",
       "        [    26,  30000],\n",
       "        [    49,  86000],\n",
       "        [    57, 122000],\n",
       "        [    34,  25000],\n",
       "        [    35,  57000],\n",
       "        [    34, 115000],\n",
       "        [    59,  88000],\n",
       "        [    45,  32000],\n",
       "        [    29,  83000],\n",
       "        [    26,  80000],\n",
       "        [    49,  28000],\n",
       "        [    23,  20000],\n",
       "        [    32,  18000],\n",
       "        [    60,  42000],\n",
       "        [    19,  76000],\n",
       "        [    36,  99000],\n",
       "        [    19,  26000],\n",
       "        [    60,  83000],\n",
       "        [    24,  89000],\n",
       "        [    27,  58000],\n",
       "        [    40,  47000],\n",
       "        [    42,  70000],\n",
       "        [    32, 150000],\n",
       "        [    35,  77000],\n",
       "        [    22,  63000],\n",
       "        [    45,  22000],\n",
       "        [    27,  89000],\n",
       "        [    18,  82000],\n",
       "        [    42,  79000],\n",
       "        [    40,  60000],\n",
       "        [    53,  34000],\n",
       "        [    47, 107000],\n",
       "        [    58, 144000],\n",
       "        [    59,  83000],\n",
       "        [    24,  55000],\n",
       "        [    26,  35000],\n",
       "        [    58,  38000],\n",
       "        [    42,  80000],\n",
       "        [    40,  75000],\n",
       "        [    59, 130000],\n",
       "        [    46,  41000],\n",
       "        [    41,  60000],\n",
       "        [    42,  64000],\n",
       "        [    37, 146000],\n",
       "        [    23,  48000],\n",
       "        [    25,  33000],\n",
       "        [    24,  84000],\n",
       "        [    27,  96000],\n",
       "        [    23,  63000],\n",
       "        [    48,  33000],\n",
       "        [    48,  90000],\n",
       "        [    42, 104000]], dtype=int64),\n",
       " array([0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign test data size 25%\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size= 0.25, random_state=0)\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scalling the input data\n",
    "sc_X = StandardScaler() \n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58164944, -0.88670699],\n",
       "       [-0.60673761,  1.46173768],\n",
       "       [-0.01254409, -0.5677824 ],\n",
       "       [-0.60673761,  1.89663484],\n",
       "       [ 1.37390747, -1.40858358],\n",
       "       [ 1.47293972,  0.99784738],\n",
       "       [ 0.08648817, -0.79972756],\n",
       "       [-0.01254409, -0.24885782],\n",
       "       [-0.21060859, -0.5677824 ],\n",
       "       [-0.21060859, -0.19087153],\n",
       "       [-0.30964085, -1.29261101],\n",
       "       [-0.30964085, -0.5677824 ],\n",
       "       [ 0.38358493,  0.09905991],\n",
       "       [ 0.8787462 , -0.59677555],\n",
       "       [ 2.06713324, -1.17663843],\n",
       "       [ 1.07681071, -0.13288524],\n",
       "       [ 0.68068169,  1.78066227],\n",
       "       [-0.70576986,  0.56295021],\n",
       "       [ 0.77971394,  0.35999821],\n",
       "       [ 0.8787462 , -0.53878926],\n",
       "       [-1.20093113, -1.58254245],\n",
       "       [ 2.1661655 ,  0.93986109],\n",
       "       [-0.01254409,  1.22979253],\n",
       "       [ 0.18552042,  1.08482681],\n",
       "       [ 0.38358493, -0.48080297],\n",
       "       [-0.30964085, -0.30684411],\n",
       "       [ 0.97777845, -0.8287207 ],\n",
       "       [ 0.97777845,  1.8676417 ],\n",
       "       [-0.01254409,  1.25878567],\n",
       "       [-0.90383437,  2.27354572],\n",
       "       [-1.20093113, -1.58254245],\n",
       "       [ 2.1661655 , -0.79972756],\n",
       "       [-1.39899564, -1.46656987],\n",
       "       [ 0.38358493,  2.30253886],\n",
       "       [ 0.77971394,  0.76590222],\n",
       "       [-1.00286662, -0.30684411],\n",
       "       [ 0.08648817,  0.76590222],\n",
       "       [-1.00286662,  0.56295021],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [ 0.68068169, -1.26361786],\n",
       "       [-0.50770535, -0.01691267],\n",
       "       [-1.79512465,  0.35999821],\n",
       "       [-0.70576986,  0.12805305],\n",
       "       [ 0.38358493,  0.30201192],\n",
       "       [-0.30964085,  0.07006676],\n",
       "       [-0.50770535,  2.30253886],\n",
       "       [ 0.18552042,  0.04107362],\n",
       "       [ 1.27487521,  2.21555943],\n",
       "       [ 0.77971394,  0.27301877],\n",
       "       [-0.30964085,  0.1570462 ],\n",
       "       [-0.01254409, -0.53878926],\n",
       "       [-0.21060859,  0.1570462 ],\n",
       "       [-0.11157634,  0.24402563],\n",
       "       [-0.01254409, -0.24885782],\n",
       "       [ 2.1661655 ,  1.11381995],\n",
       "       [-1.79512465,  0.35999821],\n",
       "       [ 1.86906873,  0.12805305],\n",
       "       [ 0.38358493, -0.13288524],\n",
       "       [-1.20093113,  0.30201192],\n",
       "       [ 0.77971394,  1.37475825],\n",
       "       [-0.30964085, -0.24885782],\n",
       "       [-1.6960924 , -0.04590581],\n",
       "       [-1.00286662, -0.74174127],\n",
       "       [ 0.28455268,  0.50496393],\n",
       "       [-0.11157634, -1.06066585],\n",
       "       [-1.10189888,  0.59194336],\n",
       "       [ 0.08648817, -0.79972756],\n",
       "       [-1.00286662,  1.54871711],\n",
       "       [-0.70576986,  1.40375139],\n",
       "       [-1.29996338,  0.50496393],\n",
       "       [-0.30964085,  0.04107362],\n",
       "       [-0.11157634,  0.01208048],\n",
       "       [-0.30964085, -0.88670699],\n",
       "       [ 0.8787462 , -1.3505973 ],\n",
       "       [-0.30964085,  2.24455257],\n",
       "       [ 0.97777845,  1.98361427],\n",
       "       [-1.20093113,  0.47597078],\n",
       "       [-1.29996338,  0.27301877],\n",
       "       [ 1.37390747,  1.98361427],\n",
       "       [ 1.27487521, -1.3505973 ],\n",
       "       [-0.30964085, -0.27785096],\n",
       "       [-0.50770535,  1.25878567],\n",
       "       [-0.80480212,  1.08482681],\n",
       "       [ 0.97777845, -1.06066585],\n",
       "       [ 0.28455268,  0.30201192],\n",
       "       [ 0.97777845,  0.76590222],\n",
       "       [-0.70576986, -1.49556302],\n",
       "       [-0.70576986,  0.04107362],\n",
       "       [ 0.48261718,  1.72267598],\n",
       "       [ 2.06713324,  0.18603934],\n",
       "       [-1.99318916, -0.74174127],\n",
       "       [-0.21060859,  1.40375139],\n",
       "       [ 0.38358493,  0.59194336],\n",
       "       [ 0.8787462 , -1.14764529],\n",
       "       [-1.20093113, -0.77073441],\n",
       "       [ 0.18552042,  0.24402563],\n",
       "       [ 0.77971394, -0.30684411],\n",
       "       [ 2.06713324, -0.79972756],\n",
       "       [ 0.77971394,  0.12805305],\n",
       "       [-0.30964085,  0.6209365 ],\n",
       "       [-1.00286662, -0.30684411],\n",
       "       [ 0.18552042, -0.3648304 ],\n",
       "       [ 2.06713324,  2.12857999],\n",
       "       [ 1.86906873, -1.26361786],\n",
       "       [ 1.37390747, -0.91570013],\n",
       "       [ 0.8787462 ,  1.25878567],\n",
       "       [ 1.47293972,  2.12857999],\n",
       "       [-0.30964085, -1.23462472],\n",
       "       [ 1.96810099,  0.91086794],\n",
       "       [ 0.68068169, -0.71274813],\n",
       "       [-1.49802789,  0.35999821],\n",
       "       [ 0.77971394, -1.3505973 ],\n",
       "       [ 0.38358493, -0.13288524],\n",
       "       [-1.00286662,  0.41798449],\n",
       "       [-0.01254409, -0.30684411],\n",
       "       [-1.20093113,  0.41798449],\n",
       "       [-0.90383437, -1.20563157],\n",
       "       [-0.11157634,  0.04107362],\n",
       "       [-1.59706014, -0.42281668],\n",
       "       [ 0.97777845, -1.00267957],\n",
       "       [ 1.07681071, -1.20563157],\n",
       "       [-0.01254409, -0.13288524],\n",
       "       [-1.10189888, -1.52455616],\n",
       "       [ 0.77971394, -1.20563157],\n",
       "       [ 0.97777845,  2.07059371],\n",
       "       [-1.20093113, -1.52455616],\n",
       "       [-0.30964085,  0.79489537],\n",
       "       [ 0.08648817, -0.30684411],\n",
       "       [-1.39899564, -1.23462472],\n",
       "       [-0.60673761, -1.49556302],\n",
       "       [ 0.77971394,  0.53395707],\n",
       "       [-0.30964085, -0.33583725],\n",
       "       [ 1.77003648, -0.27785096],\n",
       "       [ 0.8787462 , -1.03167271],\n",
       "       [ 0.18552042,  0.07006676],\n",
       "       [-0.60673761,  0.8818748 ],\n",
       "       [-1.89415691, -1.40858358],\n",
       "       [-1.29996338,  0.59194336],\n",
       "       [-0.30964085,  0.53395707],\n",
       "       [-1.00286662, -1.089659  ],\n",
       "       [ 1.17584296, -1.43757673],\n",
       "       [ 0.18552042, -0.30684411],\n",
       "       [ 1.17584296, -0.74174127],\n",
       "       [-0.30964085,  0.07006676],\n",
       "       [ 0.18552042,  2.09958685],\n",
       "       [ 0.77971394, -1.089659  ],\n",
       "       [ 0.08648817,  0.04107362],\n",
       "       [-1.79512465,  0.12805305],\n",
       "       [-0.90383437,  0.1570462 ],\n",
       "       [-0.70576986,  0.18603934],\n",
       "       [ 0.8787462 , -1.29261101],\n",
       "       [ 0.18552042, -0.24885782],\n",
       "       [-0.4086731 ,  1.22979253],\n",
       "       [-0.01254409,  0.30201192],\n",
       "       [ 0.38358493,  0.1570462 ],\n",
       "       [ 0.8787462 , -0.65476184],\n",
       "       [ 0.08648817,  0.1570462 ],\n",
       "       [-1.89415691, -1.29261101],\n",
       "       [-0.11157634,  0.30201192],\n",
       "       [-0.21060859, -0.27785096],\n",
       "       [ 0.28455268, -0.50979612],\n",
       "       [-0.21060859,  1.6067034 ],\n",
       "       [ 0.97777845, -1.17663843],\n",
       "       [-0.21060859,  1.63569655],\n",
       "       [ 1.27487521,  1.8676417 ],\n",
       "       [-1.10189888, -0.3648304 ],\n",
       "       [-0.01254409,  0.04107362],\n",
       "       [ 0.08648817, -0.24885782],\n",
       "       [-1.59706014, -1.23462472],\n",
       "       [-0.50770535, -0.27785096],\n",
       "       [ 0.97777845,  0.12805305],\n",
       "       [ 1.96810099, -1.3505973 ],\n",
       "       [ 1.47293972,  0.07006676],\n",
       "       [-0.60673761,  1.37475825],\n",
       "       [ 1.57197197,  0.01208048],\n",
       "       [-0.80480212,  0.30201192],\n",
       "       [ 1.96810099,  0.73690908],\n",
       "       [-1.20093113, -0.50979612],\n",
       "       [ 0.68068169,  0.27301877],\n",
       "       [-1.39899564, -0.42281668],\n",
       "       [ 0.18552042,  0.1570462 ],\n",
       "       [-0.50770535, -1.20563157],\n",
       "       [ 0.58164944,  2.01260742],\n",
       "       [-1.59706014, -1.49556302],\n",
       "       [-0.50770535, -0.53878926],\n",
       "       [ 0.48261718,  1.83864855],\n",
       "       [-1.39899564, -1.089659  ],\n",
       "       [ 0.77971394, -1.37959044],\n",
       "       [-0.30964085, -0.42281668],\n",
       "       [ 1.57197197,  0.99784738],\n",
       "       [ 0.97777845,  1.43274454],\n",
       "       [-0.30964085, -0.48080297],\n",
       "       [-0.11157634,  2.15757314],\n",
       "       [-1.49802789, -0.1038921 ],\n",
       "       [-0.11157634,  1.95462113],\n",
       "       [-0.70576986, -0.33583725],\n",
       "       [-0.50770535, -0.8287207 ],\n",
       "       [ 0.68068169, -1.37959044],\n",
       "       [-0.80480212, -1.58254245],\n",
       "       [-1.89415691, -1.46656987],\n",
       "       [ 1.07681071,  0.12805305],\n",
       "       [ 0.08648817,  1.51972397],\n",
       "       [-0.30964085,  0.09905991],\n",
       "       [ 0.08648817,  0.04107362],\n",
       "       [-1.39899564, -1.3505973 ],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [-0.90383437,  0.38899135],\n",
       "       [ 1.57197197, -1.26361786],\n",
       "       [-0.30964085, -0.74174127],\n",
       "       [-0.11157634,  0.1570462 ],\n",
       "       [-0.90383437, -0.65476184],\n",
       "       [-0.70576986, -0.04590581],\n",
       "       [ 0.38358493, -0.45180983],\n",
       "       [-0.80480212,  1.89663484],\n",
       "       [ 1.37390747,  1.28777882],\n",
       "       [ 1.17584296, -0.97368642],\n",
       "       [ 1.77003648,  1.83864855],\n",
       "       [-0.90383437, -0.24885782],\n",
       "       [-0.80480212,  0.56295021],\n",
       "       [-1.20093113, -1.5535493 ],\n",
       "       [-0.50770535, -1.11865214],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [-0.21060859, -1.06066585],\n",
       "       [ 1.67100423,  1.6067034 ],\n",
       "       [ 0.97777845,  1.78066227],\n",
       "       [ 0.28455268,  0.04107362],\n",
       "       [-0.80480212, -0.21986468],\n",
       "       [-0.11157634,  0.07006676],\n",
       "       [ 0.28455268, -0.19087153],\n",
       "       [ 1.96810099, -0.65476184],\n",
       "       [-0.80480212,  1.3457651 ],\n",
       "       [-1.79512465, -0.59677555],\n",
       "       [-0.11157634,  0.12805305],\n",
       "       [ 0.28455268, -0.30684411],\n",
       "       [ 1.07681071,  0.56295021],\n",
       "       [-1.00286662,  0.27301877],\n",
       "       [ 1.47293972,  0.35999821],\n",
       "       [ 0.18552042, -0.3648304 ],\n",
       "       [ 2.1661655 , -1.03167271],\n",
       "       [-0.30964085,  1.11381995],\n",
       "       [-1.6960924 ,  0.07006676],\n",
       "       [-0.01254409,  0.04107362],\n",
       "       [ 0.08648817,  1.05583366],\n",
       "       [-0.11157634, -0.3648304 ],\n",
       "       [-1.20093113,  0.07006676],\n",
       "       [-0.30964085, -1.3505973 ],\n",
       "       [ 1.57197197,  1.11381995],\n",
       "       [-0.80480212, -1.52455616],\n",
       "       [ 0.08648817,  1.8676417 ],\n",
       "       [-0.90383437, -0.77073441],\n",
       "       [-0.50770535, -0.77073441],\n",
       "       [-0.30964085, -0.91570013],\n",
       "       [ 0.28455268, -0.71274813],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [ 0.08648817,  1.8676417 ],\n",
       "       [-1.10189888,  1.95462113],\n",
       "       [-1.6960924 , -1.5535493 ],\n",
       "       [-1.20093113, -1.089659  ],\n",
       "       [-0.70576986, -0.1038921 ],\n",
       "       [ 0.08648817,  0.09905991],\n",
       "       [ 0.28455268,  0.27301877],\n",
       "       [ 0.8787462 , -0.5677824 ],\n",
       "       [ 0.28455268, -1.14764529],\n",
       "       [-0.11157634,  0.67892279],\n",
       "       [ 2.1661655 , -0.68375498],\n",
       "       [-1.29996338, -1.37959044],\n",
       "       [-1.00286662, -0.94469328],\n",
       "       [-0.01254409, -0.42281668],\n",
       "       [-0.21060859, -0.45180983],\n",
       "       [-1.79512465, -0.97368642],\n",
       "       [ 1.77003648,  0.99784738],\n",
       "       [ 0.18552042, -0.3648304 ],\n",
       "       [ 0.38358493,  1.11381995],\n",
       "       [-1.79512465, -1.3505973 ],\n",
       "       [ 0.18552042, -0.13288524],\n",
       "       [ 0.8787462 , -1.43757673],\n",
       "       [-1.99318916,  0.47597078],\n",
       "       [-0.30964085,  0.27301877],\n",
       "       [ 1.86906873, -1.06066585],\n",
       "       [-0.4086731 ,  0.07006676],\n",
       "       [ 1.07681071, -0.88670699],\n",
       "       [-1.10189888, -1.11865214],\n",
       "       [-1.89415691,  0.01208048],\n",
       "       [ 0.08648817,  0.27301877],\n",
       "       [-1.20093113,  0.33100506],\n",
       "       [-1.29996338,  0.30201192],\n",
       "       [-1.00286662,  0.44697764],\n",
       "       [ 1.67100423, -0.88670699],\n",
       "       [ 1.17584296,  0.53395707],\n",
       "       [ 1.07681071,  0.53395707],\n",
       "       [ 1.37390747,  2.331532  ],\n",
       "       [-0.30964085, -0.13288524],\n",
       "       [ 0.38358493, -0.45180983],\n",
       "       [-0.4086731 , -0.77073441],\n",
       "       [-0.11157634, -0.50979612],\n",
       "       [ 0.97777845, -1.14764529],\n",
       "       [-0.90383437, -0.77073441],\n",
       "       [-0.21060859, -0.50979612],\n",
       "       [-1.10189888, -0.45180983],\n",
       "       [-1.20093113,  1.40375139]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.54748976,  0.5130727 ],\n",
       "       [ 0.15442019, -0.61825566],\n",
       "       [-0.10879604,  0.14615539],\n",
       "       [-0.54748976,  0.26846116],\n",
       "       [-0.10879604, -0.61825566],\n",
       "       [-0.81070599, -1.53554892],\n",
       "       [-0.45975102, -1.68843113],\n",
       "       [-0.0210573 ,  2.25592989],\n",
       "       [-1.60035469, -0.0678797 ],\n",
       "       [ 0.94406888, -0.83229075],\n",
       "       [-0.54748976, -0.6488321 ],\n",
       "       [-0.72296725, -0.46537345],\n",
       "       [ 0.06668145, -0.46537345],\n",
       "       [ 0.24215893,  0.20730828],\n",
       "       [-1.4248772 ,  0.48249625],\n",
       "       [-0.37201227,  1.43036596],\n",
       "       [ 0.06668145,  0.20730828],\n",
       "       [-1.51261594,  0.45191981],\n",
       "       [ 1.64597884,  1.8278597 ],\n",
       "       [-0.10879604, -1.47439603],\n",
       "       [-0.10879604, -0.70998498],\n",
       "       [ 0.94406888,  2.25592989],\n",
       "       [ 0.41763642, -0.58767922],\n",
       "       [ 0.94406888,  1.06344865],\n",
       "       [-1.16166097, -1.29093738],\n",
       "       [ 1.11954637,  2.16420057],\n",
       "       [-0.72296725,  0.5130727 ],\n",
       "       [-0.63522851,  0.2990376 ],\n",
       "       [ 0.06668145, -0.25133835],\n",
       "       [-0.37201227,  0.48249625],\n",
       "       [-1.33713846,  0.54364914],\n",
       "       [ 0.06668145,  0.26846116],\n",
       "       [ 1.82145632, -0.31249124],\n",
       "       [ 0.06668145, -0.52652633],\n",
       "       [-1.07392223, -0.37364412],\n",
       "       [-1.60035469, -0.55710277],\n",
       "       [-1.24939971,  0.32961404],\n",
       "       [-0.19653479, -0.83229075],\n",
       "       [-0.45975102, -1.10747873],\n",
       "       [ 1.11954637, -1.04632585],\n",
       "       [-0.81070599,  0.54364914],\n",
       "       [ 0.41763642, -0.55710277],\n",
       "       [-0.81070599,  0.42134337],\n",
       "       [-0.10879604, -1.53554892],\n",
       "       [ 0.59311391,  1.27748375],\n",
       "       [-0.81070599, -0.37364412],\n",
       "       [ 0.06668145,  0.2990376 ],\n",
       "       [ 1.3827626 ,  0.60480202],\n",
       "       [-0.89844474, -1.2297845 ],\n",
       "       [ 1.11954637,  0.48249625],\n",
       "       [ 1.82145632,  1.58324817],\n",
       "       [-0.19653479, -1.38266671],\n",
       "       [-0.10879604, -0.40422056],\n",
       "       [-0.19653479,  1.36921307],\n",
       "       [ 1.99693381,  0.54364914],\n",
       "       [ 0.7685914 , -1.16863161],\n",
       "       [-0.63522851,  0.39076693],\n",
       "       [-0.89844474,  0.2990376 ],\n",
       "       [ 1.11954637, -1.29093738],\n",
       "       [-1.16166097, -1.53554892],\n",
       "       [-0.37201227, -1.5967018 ],\n",
       "       [ 2.08467255, -0.86286719],\n",
       "       [-1.51261594,  0.17673183],\n",
       "       [-0.0210573 ,  0.87999   ],\n",
       "       [-1.51261594, -1.35209027],\n",
       "       [ 2.08467255,  0.39076693],\n",
       "       [-1.07392223,  0.57422558],\n",
       "       [-0.81070599, -0.37364412],\n",
       "       [ 0.32989768, -0.70998498],\n",
       "       [ 0.50537516, -0.00672682],\n",
       "       [-0.37201227,  2.43938854],\n",
       "       [-0.10879604,  0.20730828],\n",
       "       [-1.24939971, -0.22076191],\n",
       "       [ 0.7685914 , -1.47439603],\n",
       "       [-0.81070599,  0.57422558],\n",
       "       [-1.60035469,  0.36019049],\n",
       "       [ 0.50537516,  0.26846116],\n",
       "       [ 0.32989768, -0.31249124],\n",
       "       [ 1.47050135, -1.10747873],\n",
       "       [ 0.94406888,  1.12460154],\n",
       "       [ 1.90919507,  2.25592989],\n",
       "       [ 1.99693381,  0.39076693],\n",
       "       [-1.07392223, -0.46537345],\n",
       "       [-0.89844474, -1.07690229],\n",
       "       [ 1.90919507, -0.98517296],\n",
       "       [ 0.50537516,  0.2990376 ],\n",
       "       [ 0.32989768,  0.14615539],\n",
       "       [ 1.99693381,  1.8278597 ],\n",
       "       [ 0.85633014, -0.89344364],\n",
       "       [ 0.41763642, -0.31249124],\n",
       "       [ 0.50537516, -0.19018547],\n",
       "       [ 0.06668145,  2.31708278],\n",
       "       [-1.16166097, -0.67940854],\n",
       "       [-0.98618348, -1.13805517],\n",
       "       [-1.07392223,  0.42134337],\n",
       "       [-0.81070599,  0.78826068],\n",
       "       [-1.16166097, -0.22076191],\n",
       "       [ 1.03180763, -1.13805517],\n",
       "       [ 1.03180763,  0.60480202],\n",
       "       [ 0.50537516,  1.03287221]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing classifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# initializaing the NB\n",
    "classifer = BernoulliNB()\n",
    "# training the model\n",
    "classifer.fit(X_train, y_train)\n",
    "# testing the model\n",
    "y_pred = classifer.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# importing accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# printing the accuracy of the model\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Gaussian Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# create a Gaussian Classifier\n",
    "classifer1 = GaussianNB()\n",
    "# training the model\n",
    "classifer1.fit(X_train, y_train)\n",
    "# testing the model\n",
    "y_pred1 = classifer1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n"
     ]
    }
   ],
   "source": [
    "# importing accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# printing the accuracy of the model\n",
    "print(accuracy_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Évaluation du classificateur Bernoulli Naive Bayes\n",
    "#matrice de confusion\n",
    "# importing the required modules\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# passing actual and predicted values\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# true write data values in each cell of the matrix\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.savefig('confusion.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86        68\n",
      "           1       0.75      0.56      0.64        32\n",
      "\n",
      "    accuracy                           0.80       100\n",
      "   macro avg       0.78      0.74      0.75       100\n",
      "weighted avg       0.79      0.80      0.79       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing classification report\n",
    "from sklearn.metrics import classification_report\n",
    "# printing the report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Évaluation du classificateur naïf gaussien de Bayes\n",
    "#matrice confusion sur y_pred1 \n",
    "# passing actual and predicted values\n",
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "# true write data values in each cell of the matrix\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('confusion.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93        68\n",
      "           1       0.87      0.84      0.86        32\n",
      "\n",
      "    accuracy                           0.91       100\n",
      "   macro avg       0.90      0.89      0.90       100\n",
      "weighted avg       0.91      0.91      0.91       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing the report\n",
    "print(classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Sunny',\n",
       "  'Sunny',\n",
       "  'Overcast',\n",
       "  'Rainy',\n",
       "  'Rainy',\n",
       "  'Rainy',\n",
       "  'Overcast',\n",
       "  'Sunny',\n",
       "  'Sunny',\n",
       "  'Rainy',\n",
       "  'Sunny',\n",
       "  'Overcast',\n",
       "  'Overcast',\n",
       "  'Rainy'],\n",
       " ['No',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'Yes',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'Yes',\n",
       "  'Yes',\n",
       "  'Yes',\n",
       "  'Yes',\n",
       "  'No'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#essayons sur exemple de donnée où il faut transformer les données non numerique en num\n",
    "#Fonctionnalités Encodage:\n",
    "#Dans la vraie vie, les données ne sont pas toujours constituées de valeurs numériques. Par exemple, playingou not playingne sont pas des valeurs numériques. Dans de tels scénarios, nous devons convertir les données non numériques en valeurs numériques avant de transmettre les données à notre modèle\n",
    "# assigning features and label variables\n",
    "weather = ['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny', 'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "# output class\n",
    "play = ['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n",
    "weather,play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le LabelEncoderconvertira les valeurs de chaîne en valeurs numériques. Par exemple, si nous imprimons la météo codée, elle ne contiendra plus de valeurs numériques.\n",
    "# Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# creating LabelEncoder\n",
    "labelCode = preprocessing.LabelEncoder()\n",
    "# Converting string labels into numbers.\n",
    "wheather_encoded=labelCode.fit_transform(weather)\n",
    "print(wheather_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n"
     ]
    }
   ],
   "source": [
    "# converting string labels into numbers.\n",
    "label=labelCode.fit_transform(play)\n",
    "print(play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[2 2 0 1 1 1 0 2 2 1 2 0 0 1].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m GaussianNB()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# train the model using the training sets\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwheather_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur2\\anaconda3\\envs\\devSalah_3Classification\\lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur2\\anaconda3\\envs\\devSalah_3Classification\\lib\\site-packages\\sklearn\\naive_bayes.py:263\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    262\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_refit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur2\\anaconda3\\envs\\devSalah_3Classification\\lib\\site-packages\\sklearn\\naive_bayes.py:423\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    422\u001b[0m first_call \u001b[38;5;241m=\u001b[39m _check_partial_fit_first_call(\u001b[38;5;28mself\u001b[39m, classes)\n\u001b[1;32m--> 423\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    425\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur2\\anaconda3\\envs\\devSalah_3Classification\\lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur2\\anaconda3\\envs\\devSalah_3Classification\\lib\\site-packages\\sklearn\\utils\\validation.py:1192\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1187\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m     )\n\u001b[1;32m-> 1192\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1208\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1210\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur2\\anaconda3\\envs\\devSalah_3Classification\\lib\\site-packages\\sklearn\\utils\\validation.py:989\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    983\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    984\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m             )\n\u001b[1;32m--> 989\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    995\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[2 2 0 1 1 1 0 2 2 1 2 0 0 1].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#entraîner le modèle\n",
    "# import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "# train the model using the training sets\n",
    "model.fit(wheather_encoded, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#Tableau de conversion\n",
    "# converting 1D array to 2D\n",
    "wheather_2d = np.reshape(wheather_encoded, (-1, 1))\n",
    "print(wheather_2d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devSalah_3Classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
