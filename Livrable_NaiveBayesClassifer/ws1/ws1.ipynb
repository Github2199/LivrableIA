{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes On The Iris Dataset\n",
    "\n",
    "from csv import reader\n",
    "from random import seed, randrange\n",
    "from math import sqrt, exp, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition des fonctions necessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file\n",
    "\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "\n",
    "    # Ouvre le fichier CSV en mode lecture ('r')\n",
    "    with open(filename, 'r') as file:\n",
    "        # Crée un objet CSV reader pour lire le contenu du fichier\n",
    "        csv_reader = reader(file)\n",
    "\n",
    "        # Parcourt chaque ligne du fichier CSV\n",
    "        for row in csv_reader:\n",
    "            # Vérifie si la ligne est vide, et passe à la ligne suivante si c'est le cas\n",
    "            if not row:\n",
    "                continue\n",
    "            \n",
    "            # Ajoute la ligne non vide à la liste dataset\n",
    "            dataset.append(row)\n",
    "\n",
    "    # Retourne la liste complète contenant toutes les lignes du fichier CSV\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#un code plus simple\n",
    "def load_csv(filename):\n",
    "    # Initialiser une liste vide pour stocker les données CSV\n",
    "    dataset = []\n",
    "\n",
    "    # Ouvrir le fichier CSV en mode lecture ('r')\n",
    "    with open(filename, 'r') as file:\n",
    "        # Créer un objet lecteur CSV pour lire le contenu du fichier\n",
    "        csv_reader = reader(file)\n",
    "        \n",
    "        # ajouter les lignes non vides à la liste dataset\n",
    "        dataset = [row for row in csv_reader if row]\n",
    "\n",
    "    # Retourner la liste contenant les lignes non vides du fichier CSV\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_column_to_float(dataset, column):\n",
    "    \"\"\"\n",
    "    Convertit la colonne de chaînes spécifiée en nombre à virgule flottante dans le jeu de données.\n",
    "\n",
    "    Args:\n",
    "    - dataset (list of lists): Le jeu de données.\n",
    "    - column (int): L'index de la colonne à convertir.\n",
    "    \"\"\"\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code plus simple en utilisation les iteration\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = {value: i for i, value in enumerate(unique)}\n",
    "\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "\n",
    "    return lookup\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = [list() for _ in range(n_folds)]\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = len(dataset) // n_folds\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = random.randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split[i] = fold\n",
    "\n",
    "    return dataset_split\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = sum(1 for i in range(len(actual)) if actual[i] == predicted[i])\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "\n",
    "    for fold in folds:\n",
    "        train_set = [row for subset in folds if subset != fold for row in subset]\n",
    "        test_set = [list(row) for row in fold]\n",
    "        for row in test_set:\n",
    "            row[-1] = None\n",
    "\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def separate_by_class(dataset):\n",
    "    separated = dict()\n",
    "    for vector in dataset:\n",
    "        class_value = vector[-1]\n",
    "        if class_value not in separated:\n",
    "            separated[class_value] = list()\n",
    "        separated[class_value].append(vector)\n",
    "\n",
    "    return separated\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers) / float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum((x - avg)**2 for x in numbers) / float(len(numbers) - 1)\n",
    "    return sqrt(variance)\n",
    "\n",
    "def summarize_dataset(dataset):\n",
    "    return [(mean(column), stdev(column), len(column)) for column in zip(*dataset)][:-1]\n",
    "\n",
    "def summarize_by_class(dataset):\n",
    "    separated = separate_by_class(dataset)\n",
    "    return {class_value: summarize_dataset(rows) for class_value, rows in separated.items()}\n",
    "\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    exponent = exp(-((x - mean)**2 / (2 * stdev**2)))\n",
    "    return (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
    "\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "    total_rows = sum(summ[0][2] for summ in summaries.values())\n",
    "    probabilities = {class_value: summ[0][2] / float(total_rows) for class_value, summ in summaries.items()}\n",
    "\n",
    "    for i, class_summaries in enumerate(summaries.values()):\n",
    "        for class_value, probability in probabilities.items():\n",
    "            mean, stdev, _ = class_summaries[i]\n",
    "            probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "def predict(summaries, row):\n",
    "    probabilities = calculate_class_probabilities(summaries, row)\n",
    "    best_label, best_prob = max(probabilities.items(), key=lambda x: x[1])\n",
    "    return best_label\n",
    "\n",
    "def naive_bayes(train, test):\n",
    "    summarize = summarize_by_class(train)\n",
    "    return [predict(summarize, row) for row in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du random pour des chiffres aleatoire de 1 à 5 pour garantir la reproductibilité des résultats\n",
    "seed(1)\n",
    "\n",
    "# Chargement du fichier CSV 'iris.csv' dans dataframe\n",
    "filename = 'C:\\\\Users\\\\Utilisateur2\\\\Documents\\\\FORM-DEVIA\\\\3-CLASSIFICATION\\\\1Naive bayes classifer\\\\ws1\\\\iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "# Conversion de chaque colonne de chaînes en nombre à virgule flottante\n",
    "# Boucle à travers toutes les colonnes sauf la dernière\n",
    "for i in range(len(dataset[0]) - 1):\n",
    "    str_column_to_float(dataset, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.1, 3.5, 1.4, 0.2, 'Iris-setosa'],\n",
       " [4.9, 3.0, 1.4, 0.2, 'Iris-setosa'],\n",
       " [4.7, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       " [4.6, 3.1, 1.5, 0.2, 'Iris-setosa'],\n",
       " [5.0, 3.6, 1.4, 0.2, 'Iris-setosa'],\n",
       " [5.4, 3.9, 1.7, 0.4, 'Iris-setosa'],\n",
       " [4.6, 3.4, 1.4, 0.3, 'Iris-setosa'],\n",
       " [5.0, 3.4, 1.5, 0.2, 'Iris-setosa'],\n",
       " [4.4, 2.9, 1.4, 0.2, 'Iris-setosa'],\n",
       " [4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       " [5.4, 3.7, 1.5, 0.2, 'Iris-setosa'],\n",
       " [4.8, 3.4, 1.6, 0.2, 'Iris-setosa'],\n",
       " [4.8, 3.0, 1.4, 0.1, 'Iris-setosa'],\n",
       " [4.3, 3.0, 1.1, 0.1, 'Iris-setosa'],\n",
       " [5.8, 4.0, 1.2, 0.2, 'Iris-setosa'],\n",
       " [5.7, 4.4, 1.5, 0.4, 'Iris-setosa'],\n",
       " [5.4, 3.9, 1.3, 0.4, 'Iris-setosa'],\n",
       " [5.1, 3.5, 1.4, 0.3, 'Iris-setosa'],\n",
       " [5.7, 3.8, 1.7, 0.3, 'Iris-setosa'],\n",
       " [5.1, 3.8, 1.5, 0.3, 'Iris-setosa'],\n",
       " [5.4, 3.4, 1.7, 0.2, 'Iris-setosa'],\n",
       " [5.1, 3.7, 1.5, 0.4, 'Iris-setosa'],\n",
       " [4.6, 3.6, 1.0, 0.2, 'Iris-setosa'],\n",
       " [5.1, 3.3, 1.7, 0.5, 'Iris-setosa'],\n",
       " [4.8, 3.4, 1.9, 0.2, 'Iris-setosa'],\n",
       " [5.0, 3.0, 1.6, 0.2, 'Iris-setosa'],\n",
       " [5.0, 3.4, 1.6, 0.4, 'Iris-setosa'],\n",
       " [5.2, 3.5, 1.5, 0.2, 'Iris-setosa'],\n",
       " [5.2, 3.4, 1.4, 0.2, 'Iris-setosa'],\n",
       " [4.7, 3.2, 1.6, 0.2, 'Iris-setosa'],\n",
       " [4.8, 3.1, 1.6, 0.2, 'Iris-setosa'],\n",
       " [5.4, 3.4, 1.5, 0.4, 'Iris-setosa'],\n",
       " [5.2, 4.1, 1.5, 0.1, 'Iris-setosa'],\n",
       " [5.5, 4.2, 1.4, 0.2, 'Iris-setosa'],\n",
       " [4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       " [5.0, 3.2, 1.2, 0.2, 'Iris-setosa'],\n",
       " [5.5, 3.5, 1.3, 0.2, 'Iris-setosa'],\n",
       " [4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       " [4.4, 3.0, 1.3, 0.2, 'Iris-setosa'],\n",
       " [5.1, 3.4, 1.5, 0.2, 'Iris-setosa'],\n",
       " [5.0, 3.5, 1.3, 0.3, 'Iris-setosa'],\n",
       " [4.5, 2.3, 1.3, 0.3, 'Iris-setosa'],\n",
       " [4.4, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       " [5.0, 3.5, 1.6, 0.6, 'Iris-setosa'],\n",
       " [5.1, 3.8, 1.9, 0.4, 'Iris-setosa'],\n",
       " [4.8, 3.0, 1.4, 0.3, 'Iris-setosa'],\n",
       " [5.1, 3.8, 1.6, 0.2, 'Iris-setosa'],\n",
       " [4.6, 3.2, 1.4, 0.2, 'Iris-setosa'],\n",
       " [5.3, 3.7, 1.5, 0.2, 'Iris-setosa'],\n",
       " [5.0, 3.3, 1.4, 0.2, 'Iris-setosa'],\n",
       " [7.0, 3.2, 4.7, 1.4, 'Iris-versicolor'],\n",
       " [6.4, 3.2, 4.5, 1.5, 'Iris-versicolor'],\n",
       " [6.9, 3.1, 4.9, 1.5, 'Iris-versicolor'],\n",
       " [5.5, 2.3, 4.0, 1.3, 'Iris-versicolor'],\n",
       " [6.5, 2.8, 4.6, 1.5, 'Iris-versicolor'],\n",
       " [5.7, 2.8, 4.5, 1.3, 'Iris-versicolor'],\n",
       " [6.3, 3.3, 4.7, 1.6, 'Iris-versicolor'],\n",
       " [4.9, 2.4, 3.3, 1.0, 'Iris-versicolor'],\n",
       " [6.6, 2.9, 4.6, 1.3, 'Iris-versicolor'],\n",
       " [5.2, 2.7, 3.9, 1.4, 'Iris-versicolor'],\n",
       " [5.0, 2.0, 3.5, 1.0, 'Iris-versicolor'],\n",
       " [5.9, 3.0, 4.2, 1.5, 'Iris-versicolor'],\n",
       " [6.0, 2.2, 4.0, 1.0, 'Iris-versicolor'],\n",
       " [6.1, 2.9, 4.7, 1.4, 'Iris-versicolor'],\n",
       " [5.6, 2.9, 3.6, 1.3, 'Iris-versicolor'],\n",
       " [6.7, 3.1, 4.4, 1.4, 'Iris-versicolor'],\n",
       " [5.6, 3.0, 4.5, 1.5, 'Iris-versicolor'],\n",
       " [5.8, 2.7, 4.1, 1.0, 'Iris-versicolor'],\n",
       " [6.2, 2.2, 4.5, 1.5, 'Iris-versicolor'],\n",
       " [5.6, 2.5, 3.9, 1.1, 'Iris-versicolor'],\n",
       " [5.9, 3.2, 4.8, 1.8, 'Iris-versicolor'],\n",
       " [6.1, 2.8, 4.0, 1.3, 'Iris-versicolor'],\n",
       " [6.3, 2.5, 4.9, 1.5, 'Iris-versicolor'],\n",
       " [6.1, 2.8, 4.7, 1.2, 'Iris-versicolor'],\n",
       " [6.4, 2.9, 4.3, 1.3, 'Iris-versicolor'],\n",
       " [6.6, 3.0, 4.4, 1.4, 'Iris-versicolor'],\n",
       " [6.8, 2.8, 4.8, 1.4, 'Iris-versicolor'],\n",
       " [6.7, 3.0, 5.0, 1.7, 'Iris-versicolor'],\n",
       " [6.0, 2.9, 4.5, 1.5, 'Iris-versicolor'],\n",
       " [5.7, 2.6, 3.5, 1.0, 'Iris-versicolor'],\n",
       " [5.5, 2.4, 3.8, 1.1, 'Iris-versicolor'],\n",
       " [5.5, 2.4, 3.7, 1.0, 'Iris-versicolor'],\n",
       " [5.8, 2.7, 3.9, 1.2, 'Iris-versicolor'],\n",
       " [6.0, 2.7, 5.1, 1.6, 'Iris-versicolor'],\n",
       " [5.4, 3.0, 4.5, 1.5, 'Iris-versicolor'],\n",
       " [6.0, 3.4, 4.5, 1.6, 'Iris-versicolor'],\n",
       " [6.7, 3.1, 4.7, 1.5, 'Iris-versicolor'],\n",
       " [6.3, 2.3, 4.4, 1.3, 'Iris-versicolor'],\n",
       " [5.6, 3.0, 4.1, 1.3, 'Iris-versicolor'],\n",
       " [5.5, 2.5, 4.0, 1.3, 'Iris-versicolor'],\n",
       " [5.5, 2.6, 4.4, 1.2, 'Iris-versicolor'],\n",
       " [6.1, 3.0, 4.6, 1.4, 'Iris-versicolor'],\n",
       " [5.8, 2.6, 4.0, 1.2, 'Iris-versicolor'],\n",
       " [5.0, 2.3, 3.3, 1.0, 'Iris-versicolor'],\n",
       " [5.6, 2.7, 4.2, 1.3, 'Iris-versicolor'],\n",
       " [5.7, 3.0, 4.2, 1.2, 'Iris-versicolor'],\n",
       " [5.7, 2.9, 4.2, 1.3, 'Iris-versicolor'],\n",
       " [6.2, 2.9, 4.3, 1.3, 'Iris-versicolor'],\n",
       " [5.1, 2.5, 3.0, 1.1, 'Iris-versicolor'],\n",
       " [5.7, 2.8, 4.1, 1.3, 'Iris-versicolor'],\n",
       " [6.3, 3.3, 6.0, 2.5, 'Iris-virginica'],\n",
       " [5.8, 2.7, 5.1, 1.9, 'Iris-virginica'],\n",
       " [7.1, 3.0, 5.9, 2.1, 'Iris-virginica'],\n",
       " [6.3, 2.9, 5.6, 1.8, 'Iris-virginica'],\n",
       " [6.5, 3.0, 5.8, 2.2, 'Iris-virginica'],\n",
       " [7.6, 3.0, 6.6, 2.1, 'Iris-virginica'],\n",
       " [4.9, 2.5, 4.5, 1.7, 'Iris-virginica'],\n",
       " [7.3, 2.9, 6.3, 1.8, 'Iris-virginica'],\n",
       " [6.7, 2.5, 5.8, 1.8, 'Iris-virginica'],\n",
       " [7.2, 3.6, 6.1, 2.5, 'Iris-virginica'],\n",
       " [6.5, 3.2, 5.1, 2.0, 'Iris-virginica'],\n",
       " [6.4, 2.7, 5.3, 1.9, 'Iris-virginica'],\n",
       " [6.8, 3.0, 5.5, 2.1, 'Iris-virginica'],\n",
       " [5.7, 2.5, 5.0, 2.0, 'Iris-virginica'],\n",
       " [5.8, 2.8, 5.1, 2.4, 'Iris-virginica'],\n",
       " [6.4, 3.2, 5.3, 2.3, 'Iris-virginica'],\n",
       " [6.5, 3.0, 5.5, 1.8, 'Iris-virginica'],\n",
       " [7.7, 3.8, 6.7, 2.2, 'Iris-virginica'],\n",
       " [7.7, 2.6, 6.9, 2.3, 'Iris-virginica'],\n",
       " [6.0, 2.2, 5.0, 1.5, 'Iris-virginica'],\n",
       " [6.9, 3.2, 5.7, 2.3, 'Iris-virginica'],\n",
       " [5.6, 2.8, 4.9, 2.0, 'Iris-virginica'],\n",
       " [7.7, 2.8, 6.7, 2.0, 'Iris-virginica'],\n",
       " [6.3, 2.7, 4.9, 1.8, 'Iris-virginica'],\n",
       " [6.7, 3.3, 5.7, 2.1, 'Iris-virginica'],\n",
       " [7.2, 3.2, 6.0, 1.8, 'Iris-virginica'],\n",
       " [6.2, 2.8, 4.8, 1.8, 'Iris-virginica'],\n",
       " [6.1, 3.0, 4.9, 1.8, 'Iris-virginica'],\n",
       " [6.4, 2.8, 5.6, 2.1, 'Iris-virginica'],\n",
       " [7.2, 3.0, 5.8, 1.6, 'Iris-virginica'],\n",
       " [7.4, 2.8, 6.1, 1.9, 'Iris-virginica'],\n",
       " [7.9, 3.8, 6.4, 2.0, 'Iris-virginica'],\n",
       " [6.4, 2.8, 5.6, 2.2, 'Iris-virginica'],\n",
       " [6.3, 2.8, 5.1, 1.5, 'Iris-virginica'],\n",
       " [6.1, 2.6, 5.6, 1.4, 'Iris-virginica'],\n",
       " [7.7, 3.0, 6.1, 2.3, 'Iris-virginica'],\n",
       " [6.3, 3.4, 5.6, 2.4, 'Iris-virginica'],\n",
       " [6.4, 3.1, 5.5, 1.8, 'Iris-virginica'],\n",
       " [6.0, 3.0, 4.8, 1.8, 'Iris-virginica'],\n",
       " [6.9, 3.1, 5.4, 2.1, 'Iris-virginica'],\n",
       " [6.7, 3.1, 5.6, 2.4, 'Iris-virginica'],\n",
       " [6.9, 3.1, 5.1, 2.3, 'Iris-virginica'],\n",
       " [5.8, 2.7, 5.1, 1.9, 'Iris-virginica'],\n",
       " [6.8, 3.2, 5.9, 2.3, 'Iris-virginica'],\n",
       " [6.7, 3.3, 5.7, 2.5, 'Iris-virginica'],\n",
       " [6.7, 3.0, 5.2, 2.3, 'Iris-virginica'],\n",
       " [6.3, 2.5, 5.0, 1.9, 'Iris-virginica'],\n",
       " [6.5, 3.0, 5.2, 2.0, 'Iris-virginica'],\n",
       " [6.2, 3.4, 5.4, 2.3, 'Iris-virginica'],\n",
       " [5.9, 3.0, 5.1, 1.8, 'Iris-virginica']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores : [20.0, 30.0, 20.0, 26.666666666666668, 33.33333333333333]\n",
      "Précision moyenne : 26.000%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Convertir la colonne de classes en entiers\n",
    "str_column_to_int(dataset, len(dataset[0]) - 1)\n",
    "\n",
    "# Évaluer l'algorithme\n",
    "n_folds = 5\n",
    "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n",
    "\n",
    "# Afficher les scores obtenus\n",
    "print('Scores : %s' % scores)\n",
    "\n",
    "# Afficher la précision moyenne en pourcentage\n",
    "print('Précision moyenne : %.3f%%' % (sum(scores) / float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iris-versicolor] => 0\n",
      "[Iris-virginica] => 1\n",
      "[Iris-setosa] => 2\n",
      "Données=[5.7, 2.9, 4.2, 1.3], Prédiction : 0\n"
     ]
    }
   ],
   "source": [
    "#irisdataset\n",
    "# Importation des modules nécessaires\n",
    "from csv import reader\n",
    "from math import sqrt, exp, pi\n",
    "\n",
    "# Charger un fichier CSV\n",
    "def charger_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# Convertir une colonne de chaînes en nombres à virgule flottante\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "# Convertir une colonne de chaînes en entiers\n",
    "def str_column_to_int(dataset, column):\n",
    "    valeurs_classes = [row[column] for row in dataset]\n",
    "    uniques = set(valeurs_classes)\n",
    "    lookup = dict()\n",
    "    for i, valeur in enumerate(uniques):\n",
    "        lookup[valeur] = i\n",
    "        print('[%s] => %d' % (valeur, i))\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "# Séparer le jeu de données par valeurs de classe, retourne un dictionnaire\n",
    "def separer_par_classe(dataset):\n",
    "    separes = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        vecteur = dataset[i]\n",
    "        valeur_classe = vecteur[-1]\n",
    "        if valeur_classe not in separes:\n",
    "            separes[valeur_classe] = list()\n",
    "        separes[valeur_classe].append(vecteur)\n",
    "    return separes\n",
    "\n",
    "# Calculer la moyenne d'une liste de nombres\n",
    "def moyenne(numbers):\n",
    "    return sum(numbers) / float(len(numbers))\n",
    "\n",
    "# Calculer l'écart-type d'une liste de nombres\n",
    "def ecart_type(numbers):\n",
    "    moy = moyenne(numbers)\n",
    "    variance = sum([(x - moy)**2 for x in numbers]) / float(len(numbers) - 1)\n",
    "    return sqrt(variance)\n",
    "\n",
    "# Calculer la moyenne, l'écart-type et le nombre d'éléments pour chaque colonne dans un jeu de données\n",
    "def resumer_jeu_de_donnees(dataset):\n",
    "    resume = [(moyenne(colonne), ecart_type(colonne), len(colonne)) for colonne in zip(*dataset)]\n",
    "    del(resume[-1])\n",
    "    return resume\n",
    "\n",
    "# Séparer le jeu de données par classe puis calculer les statistiques pour chaque ligne\n",
    "def resumer_par_classe(dataset):\n",
    "    separes = separer_par_classe(dataset)\n",
    "    resume = dict()\n",
    "    for valeur_classe, lignes in separes.items():\n",
    "        resume[valeur_classe] = resumer_jeu_de_donnees(lignes)\n",
    "    return resume\n",
    "\n",
    "# Calculer la fonction de distribution de probabilité gaussienne pour x\n",
    "def calculer_probabilite(x, moyenne, ecart_type):\n",
    "    exponentiel = exp(-((x - moyenne)**2 / (2 * ecart_type**2)))\n",
    "    return (1 / (sqrt(2 * pi) * ecart_type)) * exponentiel\n",
    "\n",
    "# Calculer les probabilités de prédire chaque classe pour une ligne donnée\n",
    "def calculer_probabilites_classe(resumes, ligne):\n",
    "    total_lignes = sum([resumes[label][0][2] for label in resumes])\n",
    "    probabilites = dict()\n",
    "    for valeur_classe, resume_classe in resumes.items():\n",
    "        probabilites[valeur_classe] = resumes[valeur_classe][0][2] / float(total_lignes)\n",
    "        for i in range(len(resume_classe)):\n",
    "            moyenne, ecart_type, _ = resume_classe[i]\n",
    "            probabilites[valeur_classe] *= calculer_probabilite(ligne[i], moyenne, ecart_type)\n",
    "    return probabilites\n",
    "\n",
    "# Prédire la classe pour une ligne donnée\n",
    "def predire(resumes, ligne):\n",
    "    probabilites = calculer_probabilites_classe(resumes, ligne)\n",
    "    meilleure_classe, meilleure_prob = None, -1\n",
    "    for valeur_classe, probabilite in probabilites.items():\n",
    "        if meilleure_classe is None or probabilite > meilleure_prob:\n",
    "            meilleure_prob = probabilite\n",
    "            meilleure_classe = valeur_classe\n",
    "    return meilleure_classe\n",
    "\n",
    "# Faire une prédiction avec Naive Bayes sur le jeu de données Iris\n",
    "nom_fichier = 'C:\\\\Users\\\\Utilisateur2\\\\Documents\\\\FORM-DEVIA\\\\3-CLASSIFICATION\\\\1Naive bayes classifer\\\\ws1\\\\iris.csv'\n",
    "jeu_de_donnees = charger_csv(nom_fichier)\n",
    "for i in range(len(jeu_de_donnees[0]) - 1):\n",
    "    str_column_to_float(jeu_de_donnees, i)\n",
    "\n",
    "# Convertir la colonne de classe en entiers\n",
    "str_column_to_int(jeu_de_donnees, len(jeu_de_donnees[0]) - 1)\n",
    "\n",
    "# Entraîner le modèle\n",
    "modele = resumer_par_classe(jeu_de_donnees)\n",
    "\n",
    "# Définir un nouvel enregistrement\n",
    "ligne = [5.7, 2.9, 4.2, 1.3]\n",
    "\n",
    "# Prédire l'étiquette\n",
    "etiquette = predire(modele, ligne)\n",
    "print('Données=%s, Prédiction : %s' % (ligne, etiquette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iris-versicolor] => 0\n",
      "[Iris-virginica] => 1\n",
      "[Iris-setosa] => 2\n",
      "Data=[5.7, 2.9, 4.2, 1.3], Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "#sur iris data\n",
    "from csv import reader\n",
    "from math import sqrt, exp, pi\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if row:\n",
    "                dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = {value: i for i, value in enumerate(unique)}\n",
    "    for value, i in lookup.items():\n",
    "        print('[%s] => %d' % (value, i))\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "# Split the dataset by class values, returns a dictionary\n",
    "def separate_by_class(dataset):\n",
    "    separated = dict()\n",
    "    for vector in dataset:\n",
    "        class_value = vector[-1]\n",
    "        if class_value not in separated:\n",
    "            separated[class_value] = list()\n",
    "        separated[class_value].append(vector)\n",
    "    return separated\n",
    "\n",
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "    return sum(numbers) / float(len(numbers))\n",
    "\n",
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum((x - avg) ** 2 for x in numbers) / float(len(numbers) - 1)\n",
    "    return sqrt(variance)\n",
    "\n",
    "# Calculate the mean, stdev and count for each column in a dataset\n",
    "def summarize_dataset(dataset):\n",
    "    summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries\n",
    "\n",
    "# Split dataset by class then calculate statistics for each row\n",
    "def summarize_by_class(dataset):\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = {class_value: summarize_dataset(rows) for class_value, rows in separated.items()}\n",
    "    return summaries\n",
    "\n",
    "# Calculate the Gaussian probability distribution function for x\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    exponent = exp(-((x - mean) ** 2 / (2 * stdev ** 2)))\n",
    "    return (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
    "\n",
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "    total_rows = sum(summaries[label][0][2] for label in summaries)\n",
    "    probabilities = {class_value: summaries[class_value][0][2] / float(total_rows) for class_value in summaries}\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev, _ = class_summaries[i]\n",
    "            probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "# Predict the class for a given row\n",
    "def predict(summaries, row):\n",
    "    probabilities = calculate_class_probabilities(summaries, row)\n",
    "    best_label, best_prob = None, -1\n",
    "    for class_value, probability in probabilities.items():\n",
    "        if best_label is None or probability > best_prob:\n",
    "            best_prob = probability\n",
    "            best_label = class_value\n",
    "    return best_label\n",
    "\n",
    "# Make a prediction with Naive Bayes on Iris Dataset\n",
    "filename = 'C:\\\\Users\\\\Utilisateur2\\\\Documents\\\\FORM-DEVIA\\\\3-CLASSIFICATION\\\\1Naive bayes classifer\\\\ws1\\\\iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0]) - 1):\n",
    "    str_column_to_float(dataset, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0]) - 1)\n",
    "# fit model\n",
    "model = summarize_by_class(dataset)\n",
    "# define a new record\n",
    "row = [5.7, 2.9, 4.2, 1.3]\n",
    "# predict the label\n",
    "label = predict(model, row)\n",
    "print('Data=%s, Predicted: %s' % (row, label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devSalah_3Classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
